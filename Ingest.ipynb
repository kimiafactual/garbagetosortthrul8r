{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "au-extracted.json\n",
      "it-extracted.json\n",
      "fr-extracted.json\n",
      "1\n",
      "gb-extracted.json\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "ca-extracted.json\n",
      "1\n",
      "2\n",
      "us-extracted.json\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "Index(['address', 'category_ids', 'country', 'file', 'id', 'locality', 'name',\n",
      "       'postcode', 'region', 'tel', 'website'],\n",
      "      dtype='object')\n",
      "Index(['_original_category', '_records_touched', 'address', 'address_accuracy',\n",
      "       'address_extended', 'address_type_code', 'admin_region', 'alcohol',\n",
      "       'alcohol_bar', 'alcohol_beer_wine', 'category_ids', 'country',\n",
      "       'cuisine', 'current', 'file', 'id', 'languages', 'locality',\n",
      "       'melissa_address_key', 'melissa_code', 'name', 'og_address', 'po_box',\n",
      "       'post_town', 'postcode', 'raw_address', 'rbdi', 'region', 'tel', 'type',\n",
      "       'website'],\n",
      "      dtype='object')\n",
      "ca-seed-inputs.json  i\n",
      "it-seed-inputs.json  i\n",
      "us-seed-inputs.json  i\n",
      "au-seed-inputs.json  i\n",
      "gb-seed-inputs.json  i\n",
      "fr-seed-inputs.json  i\n",
      "Index(['id', 'sourceUrl', 'task_id', 'user_id', 'file'], dtype='object')\n",
      "Index(['id', 'sourceUrl', 'task_id', 'user_id', 'file_x', '_original_category',\n",
      "       '_records_touched', 'address', 'address_accuracy', 'address_extended',\n",
      "       'address_type_code', 'admin_region', 'alcohol', 'alcohol_bar',\n",
      "       'alcohol_beer_wine', 'category_ids', 'country', 'cuisine', 'current',\n",
      "       'file_y', 'languages', 'locality', 'melissa_address_key',\n",
      "       'melissa_code', 'name', 'og_address', 'po_box', 'post_town', 'postcode',\n",
      "       'raw_address', 'rbdi', 'region', 'tel', 'type', 'website', 'cleansite',\n",
      "       'cleanadd', 'cleanname', 'cleantel'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Important notes: All those greater than 5 had consensus.\n",
    "import numpy as np\n",
    "from IPython.core.display import HTML\n",
    "import json\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## THIS IS THE FINAL JUN 8 at 3\n",
    "finaltaskusdf = pd.DataFrame()\n",
    "finallocdf = pd.DataFrame()\n",
    "data = {}\n",
    "all_df= []\n",
    "df_s = pd.DataFrame()\n",
    "files =  ['au-extracted.json','it-extracted.json', \n",
    "          'fr-extracted.json','gb-extracted.json',\n",
    "             'ca-extracted.json', 'us-extracted.json']\n",
    "              \n",
    "\n",
    "for file_num, file_name in enumerate(files):\n",
    "    data = {}\n",
    "    print(str(file_name))\n",
    "    n=0\n",
    "    with open('/Users/kimia/Documents/Work5/sprint614/' + str(file_name)) as f:\n",
    "            \n",
    "                for line in f:\n",
    "                    try:\n",
    "\n",
    "                        data.update(json.loads( line.rstrip('\\n')))\n",
    "                        all_df.append(data)\n",
    "\n",
    "                        taskusedits = pd.Series(data['data']['extraction']['payload']).to_frame().T\n",
    "                        taskusedits['id'] = (data['uri'])\n",
    "                        taskusedits['file'] = str(file_name)\n",
    "\n",
    "                        locdf = pd.Series(data['data']['extraction']['rawPayload']).to_frame().T\n",
    "                        locdf['id'] = (data['uri'])\n",
    "                        locdf['file'] = str(file_name)\n",
    "\n",
    "\n",
    "                        finaltaskusdf = pd.concat([taskusedits, finaltaskusdf], axis=0)\n",
    "                        finallocdf = pd.concat([locdf, finallocdf], axis=0)\n",
    "       \n",
    "                    except:\n",
    "\n",
    "                        n = n+1\n",
    "                        print(n)\n",
    "finallocdf['id'] = finallocdf['id'].apply(lambda x: int(x[-6:]))\n",
    "finaltaskusdf['id']= finaltaskusdf['id'].apply(lambda x: int(x[-6:]))\n",
    "print(finallocdf.columns)\n",
    "print(finaltaskusdf.columns)\n",
    "## THIS WORK!! 1:36 JUN 7\n",
    "data = {}\n",
    "df_s = pd.DataFrame()\n",
    "files = ['ca-seed-inputs.json' ,\n",
    "             'it-seed-inputs.json', 'us-seed-inputs.json', 'au-seed-inputs.json', \n",
    "             'gb-seed-inputs.json' , \n",
    "             'fr-seed-inputs.json']\n",
    "for file_num, file_name in enumerate(files):\n",
    "\n",
    "    print(str(file_name)+\"  i\")\n",
    "    with open('/Users/kimia/Documents/Work5/sprint614/' + str(file_name)) as f:\n",
    "        \n",
    "        \n",
    "        for line in f:\n",
    "            data.update(json.loads( line.rstrip('\\n')))\n",
    "            #print(data['data']['extraction']['inputMeta'])\n",
    "\n",
    "            d1 = pd.Series(data['data']['extraction']['inputMeta']).to_frame().T \n",
    "        \n",
    "            d1['file'] = str(file_name)\n",
    "            df_s = pd.concat([df_s, d1], axis=0)\n",
    "print(df_s.columns)       \n",
    "result = (pd.merge(df_s,finaltaskusdf, on = ['id'])) # correct merge: (result.file_x == result.file_y)\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "result['cleansite'] =result['website'].apply(lambda x: urlparse(str(x)).netloc)\n",
    "result['cleansite'] =result['cleansite'].apply(lambda x: (str(x).replace(\"www.\", \"\")))\n",
    "result['cleanadd'] = (result.address).apply(lambda x: str(x).lower())\n",
    "result['cleanname'] = (result.name).apply(lambda x: str(x).lower())\n",
    "result['cleantel'] = result['tel'].apply(lambda x: ((str(x).replace(\" \", \"\"))))\n",
    "result['cleantel'] = result['cleantel'].apply(lambda x: ((str(x).replace(\")\", \"\"))))\n",
    "result['cleantel'] = result['cleantel'].apply(lambda x: ((str(x).replace(\"(\", \"\"))))\n",
    "result['cleantel'] = result['cleantel'].apply(lambda x: ((str(x).replace(\"-\", \"\"))))\n",
    "print(result.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columnsz = ['_records_touched',\n",
    " 'address',\n",
    " 'address_accuracy',\n",
    " 'address_extended',\n",
    " 'address_type_code',\n",
    " 'admin_region',\n",
    " 'alcohol',\n",
    " 'alcohol_bar',\n",
    " 'alcohol_beer_wine','country',\n",
    " 'cuisine',\n",
    " 'current',\n",
    " 'file_y',\n",
    " 'locality',\n",
    " 'melissa_address_key',\n",
    " 'melissa_code',\n",
    " 'name',\n",
    " 'og_address',\n",
    " 'po_box',\n",
    " 'post_town',\n",
    " 'postcode',\n",
    " 'raw_address',\n",
    " 'rbdi',\n",
    " 'region',\n",
    " 'tel',\n",
    " 'type',\n",
    " 'website',]\n",
    "final = pd.DataFrame()\n",
    "accuracydict={}\n",
    "for number,country in enumerate(result.file_x.unique()):\n",
    "    for i, v in enumerate(columnsz): \n",
    "        cunt = result\n",
    "        lowagreement = cunt.groupby([ 'task_id',str(v)]).size().to_frame(name = 'count').reset_index()\n",
    "        df4agree = (lowagreement[lowagreement['task_id'].duplicated(keep=False)])\n",
    "        perc5 = ( len(df4agree[df4agree['count'] ==4].task_id.unique())/len(result.task_id.unique()))\n",
    "        percent = ({str(v):perc5})\n",
    "        accuracydict.update(percent)\n",
    "\n",
    "    all_perc_disagree = pd.Series(accuracydict).to_frame().sort_values([0],ascending = True)\n",
    "    all_perc_disagree.columns = [(str(country[0:2])).upper()]\n",
    "    final = pd.concat([all_perc_disagree, final], axis=1)\n",
    "    #print(\"% disagreement by column in \",str(country[0:2]) )\n",
    "print(\"    MODERATION: % there is consensus among 5 on a POI, by field input\")\n",
    "display(HTML(((final).to_html())))\n",
    "final.rename(index={'cleanadd': 'Address','cleanname': 'Name' , 'cleansite':'Website', 'cleantel': 'Tel'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.file_y = result.file_y.apply(lambda x: str(x)[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######## new file\n",
    "import numpy as np\n",
    "from IPython.core.display import HTML\n",
    "import json\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "attribute = 'cleanname'\n",
    "\n",
    "## determine when there is 100% consensus or all but one (usually 80%)\n",
    "## --->>> 5 people don't always annotate it, so it's better to do %. \n",
    "def consensus_on_an_attribute(df, attribute):\n",
    "    consensus_metric = df.groupby([ 'task_id', str(attribute)]).size().to_frame(name = 'consensus').reset_index()\n",
    "    total_annotators = df.groupby([ 'task_id', ]).size().to_frame(name = 'total').reset_index()\n",
    "    consensus_metric = pd.merge(consensus_metric,total_annotators, on='task_id' )\n",
    "    consensus_metric['%_consensus'] = consensus_metric['consensus']/consensus_metric['total']\n",
    "    consensus_metric_4ormore = consensus_metric[consensus_metric['%_consensus'] > .7][['task_id', str(attribute)]]\n",
    "    return consensus_metric_4ormore\n",
    "\n",
    "### example\n",
    "#attribute = 'cleanname'\n",
    "#consensus_on_an_attribute(df, attribute)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new file\n",
    "\n",
    "## when we iterate over all of the attributes, we can see that not all attributes get filled.\n",
    "#### for example, one task_id may have consensus on name, but not on address. \n",
    "## therefore, we depend on top performers to make the difference\n",
    "\n",
    "\n",
    "#who are the top people?\n",
    "\n",
    "test = result.groupby([ 'unique', str('annotation')]).size().to_frame(name = 'count').reset_index()\n",
    "\n",
    "consen = (test[test['count']>4])\n",
    "\n",
    "consen = pd.merge(consen, dfpayloads, on='unique', how='left')\n",
    "\n",
    "#count number of times consensus\n",
    "cnt = Counter()\n",
    "for word in list(consen.user_id):\n",
    "     cnt[word] += 1\n",
    "\n",
    "d={}\n",
    "\n",
    "for key, value in cnt.items():\n",
    "    d[key] = value\n",
    "\n",
    "#count number of times total\n",
    "cnt = Counter()\n",
    "for word in list(dfpayloads['user_id']):\n",
    "     cnt[word] += 1\n",
    "\n",
    "t={}\n",
    "\n",
    "for key, value in cnt.items():\n",
    "    t[key] = value\n",
    "## merge the two\n",
    "d = pd.DataFrame.from_dict(d, orient='index').reset_index()\n",
    "t = pd.DataFrame.from_dict(t, orient='index').reset_index()\n",
    "final = pd.merge(d,t , on = 'index')\n",
    "final['%'] = final['0_x']/final['0_y']\n",
    "final.sort_values(['%'], ascending = False)\n",
    "final = final.rename(columns={\"index\": \"user_id\"})\n",
    "final[\"user_id\"] = final[\"user_id\"].apply(lambda x: int(x))\n",
    "\n",
    "## top people\n",
    "top15 = list(final.sort_values(['%'], ascending = False).user_id[0:15])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: cleanname, dtype: object)\n",
      "cleanname : 0.8809980806142035\n",
      "Series([], Name: cleanname, dtype: object)\n",
      "cleantel : 0.7946257197696737\n",
      "48    comunità san luigi dei francesi\n",
      "Name: cleanname, dtype: object\n",
      "cleansite : 0.744721689059501\n",
      "Series([], Name: cleanname, dtype: object)\n",
      "cleanadd : 0.736084452975048\n",
      "Series([], Name: cleanname, dtype: object)\n",
      "postcode : 0.9001919385796545\n",
      "Series([], Name: cleanname, dtype: object)\n",
      "locality : 0.9328214971209213\n",
      "Series([], Name: cleanname, dtype: object)\n",
      "region : 0.9692898272552783\n",
      "Series([], Name: cleanname, dtype: object)\n",
      "country : 0.9769673704414588\n"
     ]
    }
   ],
   "source": [
    "df_4_Yenny = pd.DataFrame()\n",
    "\n",
    "for i,v in enumerate(['cleanname', 'cleantel', 'cleansite', 'cleanadd', 'postcode', \n",
    "                      'locality','region', 'country', ]): \n",
    "    df = result.fillna('nan')\n",
    "    #df.file_y = df.file_y.apply(lambda x: str(x)[0:2])\n",
    "    df['category_ids'] = df['category_ids'].apply(lambda x: str(x)[1:-1])\n",
    "    jk = df.groupby([ 'task_id', str(v)]).size().to_frame(name = 'count').reset_index()\n",
    "    jk = jk[jk['count']==4]\n",
    "    \n",
    "    con4df = result[result['task_id'].isin(list(jk.task_id.unique()))] # pull only those with 4 consensus \n",
    "    con4df = con4df.groupby([ 'task_id', str(v)]).size().to_frame(name = 'count').reset_index()\n",
    "    singleout = con4df[con4df['count']==1]\n",
    "    singleout = pd.merge(singleout,result, on =['task_id', (str(v))],  how = 'left')\n",
    "    \n",
    "    print(singleout[singleout.task_id ==59338]['cleanname'])\n",
    "    \n",
    "    result['unique'] = (result.task_id).apply(lambda x: str(x)) + (result.user_id).apply(lambda x: str(x))\n",
    "    singleout['unique'] = (singleout.task_id).apply(lambda x: str(x)) + (singleout.user_id).apply(lambda x: str(x))\n",
    "    \n",
    "    \n",
    "    ## rid DF of poor options\n",
    "    tasks_to_delete = list(singleout['unique'].unique())\n",
    "    df = result\n",
    "    for i,unique_id in enumerate(tasks_to_delete): \n",
    "\n",
    "        df = df[df['unique'] != (str(unique_id))]\n",
    "    df2 = df[['task_id', str(v)]].groupby([ 'task_id', str(v)]).size().to_frame(name = 'count').reset_index()\n",
    "    df5consensus = (df2[df2['count'] == 5])\n",
    "    df5consensus = df5consensus[['task_id', str(v)]]\n",
    "    df4consensus = (df2[df2['count'] == 4])\n",
    "    df4consensus = df4consensus[['task_id', str(v)]]\n",
    "    df_cleanname = pd.concat([df4consensus, df5consensus])\n",
    "    print(v, \":\", len(df_cleanname.task_id.unique())/len(result.task_id.unique()))\n",
    "    df_4_Yenny = pd.concat([df_4_Yenny, df_cleanname] ,axis =0)\n",
    "\n",
    "\n",
    "\n",
    "df_4_Yenny = df_4_Yenny.fillna('')\n",
    "df_4_Yenny = df_4_Yenny.groupby('task_id').agg(''.join)\n",
    "df_4_Yenny = df_4_Yenny.replace('', np.nan, regex=True)\n",
    "df_4_Yenny = df_4_Yenny.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302    NaN\n",
       "Name: cleanname, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4_Yenny[df_4_Yenny.task_id ==59338]['cleanname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sourceUrl</th>\n",
       "      <th>task_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>file_x</th>\n",
       "      <th>_original_category</th>\n",
       "      <th>_records_touched</th>\n",
       "      <th>address</th>\n",
       "      <th>address_accuracy</th>\n",
       "      <th>address_extended</th>\n",
       "      <th>...</th>\n",
       "      <th>rbdi</th>\n",
       "      <th>region</th>\n",
       "      <th>tel</th>\n",
       "      <th>type</th>\n",
       "      <th>website</th>\n",
       "      <th>cleansite</th>\n",
       "      <th>cleanadd</th>\n",
       "      <th>cleanname</th>\n",
       "      <th>cleantel</th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result.name =='Boch Center']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9884836852207294\n",
      "0.9932821497120922\n",
      "0.6372360844529751\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 't44' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-06425d0610c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt44\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'task_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m      \u001b[0mcnt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't44' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(df_4_Yenny.task_id.unique())/len(result.task_id.unique()))\n",
    "top_perf = result[ (result.user_id == 43)| \n",
    "                  (result.user_id == 47) |  (result.user_id == 58) ]\n",
    "\n",
    "                   #(result.user_id == 59)|  (result.user_id == 38)|  (result.user_id == 26)]\n",
    "top_perf = top_perf[['user_id', 'task_id','cleanname', 'cleantel', 'cleansite', 'cleanadd', 'postcode', \n",
    "                     'locality','region', 'country',]]\n",
    "\n",
    "df_gold_and_top = pd.concat([top_perf, df_4_Yenny])\n",
    "print(len(df_gold_and_top.task_id.unique())/len(result.task_id.unique()))\n",
    "\n",
    "df_gold_and_top['user_id'] = df_gold_and_top['user_id'].fillna('gold')\n",
    "df_gold = df_gold_and_top.groupby(['task_id','cleanname', 'cleantel', 'cleansite', 'cleanadd', 'postcode', \n",
    "                     'locality','region', 'country',]).size().to_frame(name = 'count').reset_index()\n",
    "\n",
    "print(len(df_gold.task_id.unique())/len(result.task_id.unique()))\n",
    "#np.sum(len(t44['count']))/len(4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### get a list of problematic dfs\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for word in list(t44['task_id']):\n",
    "     cnt[word] += 1\n",
    "d={}\n",
    "for key, value in cnt.items():\n",
    "    d[key] = value\n",
    "\n",
    "d = pd.DataFrame.from_dict(d, orient='index').reset_index()\n",
    "d = d[d[0]>1].reset_index()\n",
    "#len(d)/len(result.task_id.unique())\n",
    "len(list(d['index']))\n",
    "\n",
    "\n",
    "\n",
    "#### remove\n",
    "\n",
    "for i,unique_id in enumerate(list(d['index'])): \n",
    "\n",
    "    df_gold = df_gold[df_gold['task_id'] != (int(unique_id))]\n",
    "\n",
    "\n",
    "notgold = df_4_Yenny[~df_4_Yenny['task_id'].isin(list(df_gold.task_id.unique()))] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_perf = result[ (result.user_id == 43)| \n",
    "                  (result.user_id == 47) |  (result.user_id == 58) |  (result.user_id == 22) \n",
    "                   | (result.user_id == 59)|  (result.user_id == 38)|  (result.user_id == 26)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gold2 = pd.merge(notgold, top_perf[['task_id','cleanname', 'cleantel', 'cleansite', 'cleanadd', 'postcode', \n",
    "                      'locality','region', 'country', ]], on='task_id')\n",
    "\n",
    "print(len(gold2)/len(notgold))\n",
    "\n",
    "v = 'cleansite'\n",
    "cleansite_x = str(v)+'_x'\n",
    "cleansite_y = str(v)+'_y'\n",
    "gold2[str(cleansite_x)].fillna(gold2[str(cleansite_y)], inplace=True)\n",
    "del gold2[str(cleansite_y)]\n",
    "gold2 = gold2.rename(index=str, columns={str(str(v)+'_x'): str(v)})\n",
    "print(v)\n",
    "\n",
    "v = 'cleanname'\n",
    "cleansite_x = str(v)+'_x'\n",
    "cleansite_y = str(v)+'_y'\n",
    "gold2[str(cleansite_x)].fillna(gold2[str(cleansite_y)], inplace=True)\n",
    "del gold2[str(cleansite_y)]\n",
    "gold2 = gold2.rename(index=str, columns={str(str(v)+'_x'): str(v)})\n",
    "print(v)\n",
    "\n",
    "v = 'cleantel'\n",
    "cleansite_x = str(v)+'_x'\n",
    "cleansite_y = str(v)+'_y'\n",
    "gold2[str(cleansite_x)].fillna(gold2[str(cleansite_y)], inplace=True)\n",
    "del gold2[str(cleansite_y)]\n",
    "gold2 = gold2.rename(index=str, columns={str(str(v)+'_x'): str(v)})\n",
    "print(v)\n",
    "\n",
    "\n",
    "v = 'cleanadd'\n",
    "cleansite_x = str(v)+'_x'\n",
    "cleansite_y = str(v)+'_y'\n",
    "gold2[str(cleansite_x)].fillna(gold2[str(cleansite_y)], inplace=True)\n",
    "del gold2[str(cleansite_y)]\n",
    "gold2 = gold2.rename(index=str, columns={str(str(v)+'_x'): str(v)})\n",
    "print(v)\n",
    "\n",
    "v = 'locality'\n",
    "cleansite_x = str(v)+'_x'\n",
    "cleansite_y = str(v)+'_y'\n",
    "gold2[str(cleansite_x)].fillna(gold2[str(cleansite_y)], inplace=True)\n",
    "del gold2[str(cleansite_y)]\n",
    "gold2 = gold2.rename(index=str, columns={str(str(v)+'_x'): str(v)})\n",
    "print(v)\n",
    "\n",
    "v = 'region'\n",
    "cleansite_x = str(v)+'_x'\n",
    "cleansite_y = str(v)+'_y'\n",
    "gold2[str(cleansite_x)].fillna(gold2[str(cleansite_y)], inplace=True)\n",
    "del gold2[str(cleansite_y)]\n",
    "gold2 = gold2.rename(index=str, columns={str(str(v)+'_x'): str(v)})\n",
    "print(v)\n",
    "\n",
    "v = 'postcode'\n",
    "cleansite_x = str(v)+'_x'\n",
    "cleansite_y = str(v)+'_y'\n",
    "gold2[str(cleansite_x)].fillna(gold2[str(cleansite_y)], inplace=True)\n",
    "del gold2[str(cleansite_y)]\n",
    "gold2 = gold2.rename(index=str, columns={str(str(v)+'_x'): str(v)})\n",
    "print(v)\n",
    "\n",
    "\n",
    "v = 'country'\n",
    "cleansite_x = str(v)+'_x'\n",
    "cleansite_y = str(v)+'_y'\n",
    "gold2[str(cleansite_x)].fillna(gold2[str(cleansite_y)], inplace=True)\n",
    "del gold2[str(cleansite_y)]\n",
    "gold2 = gold2.rename(index=str, columns={str(str(v)+'_x'): str(v)})\n",
    "print(v)\n",
    "\n",
    "print(len(df_gold.task_id.unique())/len(result.task_id.unique()))\n",
    "print(len(gold2.task_id.unique())/len(result.task_id.unique()))\n",
    "df_gold = pd.concat([df_gold, gold2])\n",
    "print(len(df_gold.task_id.unique())/len(result.task_id.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notgold = df_4_Yenny[~df_4_Yenny['task_id'].isin(list(df_gold.task_id.unique()))] \n",
    "len(notgold.task_id.unique())/len(result.task_id.unique())\n",
    "\n",
    "\n",
    "top_perf = result[ (result.user_id == 20)| \n",
    "                  (result.user_id == 21) |  (result.user_id == 25) |  (result.user_id == 33) \n",
    "                   | (result.user_id == 31)]\n",
    "\n",
    "\n",
    "gold2 = pd.merge(notgold, top_perf[['task_id','cleanname', 'cleantel', 'cleansite', 'cleanadd', 'postcode', \n",
    "                      'locality','region', 'country', ]], on='task_id')\n",
    "\n",
    "print(len(gold2)/len(notgold))\n",
    "\n",
    "v = 'cleansite'\n",
    "cleansite_x = str(v)+'_x'\n",
    "cleansite_y = str(v)+'_y'\n",
    "gold2[str(cleansite_x)].fillna(gold2[str(cleansite_y)], inplace=True)\n",
    "del gold2[str(cleansite_y)]\n",
    "gold2 = gold2.rename(index=str, columns={str(str(v)+'_x'): str(v)})\n",
    "print(v)\n",
    "\n",
    "v = 'cleanname'\n",
    "cleansite_x = str(v)+'_x'\n",
    "cleansite_y = str(v)+'_y'\n",
    "gold2[str(cleansite_x)].fillna(gold2[str(cleansite_y)], inplace=True)\n",
    "del gold2[str(cleansite_y)]\n",
    "gold2 = gold2.rename(index=str, columns={str(str(v)+'_x'): str(v)})\n",
    "print(v)\n",
    "\n",
    "v = 'cleantel'\n",
    "cleansite_x = str(v)+'_x'\n",
    "cleansite_y = str(v)+'_y'\n",
    "gold2[str(cleansite_x)].fillna(gold2[str(cleansite_y)], inplace=True)\n",
    "del gold2[str(cleansite_y)]\n",
    "gold2 = gold2.rename(index=str, columns={str(str(v)+'_x'): str(v)})\n",
    "print(v)\n",
    "\n",
    "\n",
    "v = 'cleanadd'\n",
    "cleansite_x = str(v)+'_x'\n",
    "cleansite_y = str(v)+'_y'\n",
    "gold2[str(cleansite_x)].fillna(gold2[str(cleansite_y)], inplace=True)\n",
    "del gold2[str(cleansite_y)]\n",
    "gold2 = gold2.rename(index=str, columns={str(str(v)+'_x'): str(v)})\n",
    "print(v)\n",
    "\n",
    "v = 'locality'\n",
    "cleansite_x = str(v)+'_x'\n",
    "cleansite_y = str(v)+'_y'\n",
    "gold2[str(cleansite_x)].fillna(gold2[str(cleansite_y)], inplace=True)\n",
    "del gold2[str(cleansite_y)]\n",
    "gold2 = gold2.rename(index=str, columns={str(str(v)+'_x'): str(v)})\n",
    "print(v)\n",
    "\n",
    "v = 'region'\n",
    "cleansite_x = str(v)+'_x'\n",
    "cleansite_y = str(v)+'_y'\n",
    "gold2[str(cleansite_x)].fillna(gold2[str(cleansite_y)], inplace=True)\n",
    "del gold2[str(cleansite_y)]\n",
    "gold2 = gold2.rename(index=str, columns={str(str(v)+'_x'): str(v)})\n",
    "print(v)\n",
    "\n",
    "v = 'postcode'\n",
    "cleansite_x = str(v)+'_x'\n",
    "cleansite_y = str(v)+'_y'\n",
    "gold2[str(cleansite_x)].fillna(gold2[str(cleansite_y)], inplace=True)\n",
    "del gold2[str(cleansite_y)]\n",
    "gold2 = gold2.rename(index=str, columns={str(str(v)+'_x'): str(v)})\n",
    "print(v)\n",
    "\n",
    "\n",
    "v = 'country'\n",
    "cleansite_x = str(v)+'_x'\n",
    "cleansite_y = str(v)+'_y'\n",
    "gold2[str(cleansite_x)].fillna(gold2[str(cleansite_y)], inplace=True)\n",
    "del gold2[str(cleansite_y)]\n",
    "gold2 = gold2.rename(index=str, columns={str(str(v)+'_x'): str(v)})\n",
    "print(v)\n",
    "\n",
    "print(len(df_gold.task_id.unique())/len(result.task_id.unique()))\n",
    "print(len(gold2.task_id.unique())/len(result.task_id.unique()))\n",
    "df_gold = pd.concat([df_gold, gold2])\n",
    "print(len(df_gold.task_id.unique())/len(result.task_id.unique()))\n",
    "\n",
    "\n",
    "notgold = df_4_Yenny[~df_4_Yenny['task_id'].isin(list(df_gold.task_id.unique()))] \n",
    "len(notgold.task_id.unique())/len(result.task_id.unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(notgold.task_id.unique()) #df_4_Yenny[df_4_Yenny.task_id ==59338]['cleanname']\n",
    "## these are the ones that are not ready for ingestion! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold = df_gold.fillna('')\n",
    "df_gold  = df_gold.replace(to_replace=r'^nan$', value='', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fix website: \n",
    "\n",
    "top_perf = result[ (result.user_id == 43)| \n",
    "                  (result.user_id == 47) |  (result.user_id == 58) |  (result.user_id == 22) \n",
    "                   | (result.user_id == 59)|  (result.user_id == 38)|  (result.user_id == 26) |(result.user_id == 20)| \n",
    "                  (result.user_id == 21) |  (result.user_id == 25) |  (result.user_id == 33) \n",
    "                   | (result.user_id == 31)]\n",
    "\n",
    "top_perf = top_perf.groupby([ 'task_id', 'website']).size().to_frame(name = 'count').reset_index()\n",
    "\n",
    "print(len(df_gold))\n",
    "print('--task_id-', len(df_gold.task_id.unique()))\n",
    "#8\t59040\thttp://www.mass.gov/eea/agencies/dcr/massparks...\t1\n",
    "#9\t59040\thttps://www.mass.gov/locations/skinner-state-park\t2\n",
    "t = pd.merge(top_perf, df_gold, on='task_id', how='right')\n",
    "print(len(t))\n",
    "print('--task_id-', len(t.task_id.unique()))\n",
    "\n",
    "t = t[~t.task_id.duplicated(keep='first')]\n",
    "print(len(t))\n",
    "print('--task_id-',len(t.task_id.unique()))\n",
    "df_gold = t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_gold['cleansite']\n",
    "df_gold = df_gold.rename(index=str, columns={'cleanadd': 'address', 'cleanname': 'name', 'cleantel': 'tel'})\n",
    "del df_gold['count_x']\n",
    "del df_gold['count_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - len(df_gold.task_id.unique())/len(result.task_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "708\n",
      "708\n",
      "708\n",
      "708\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import codecs\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import matplotlib as m\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "#Yenny's dups file\n",
    "json_file = \"/Users/kimia/Desktop/Work5/sprint614/work5_batch_108_results_1531247573.json\"\n",
    "df = pd.read_json(json_file, lines=True)\n",
    "dfsub = json_normalize(df.submission)\n",
    "dftask = json_normalize(df.task)\n",
    "\n",
    "\n",
    "\n",
    "uuiddf = dftask[['payload.existingRecord.uuid', 'payload.factual_id', 'id','payload.existingRecord.latitude', 'payload.existingRecord.longitude' ]]\n",
    "uuiddf['task_id'] = uuiddf['id']\n",
    "del uuiddf['id']\n",
    "uuiddf = uuiddf[~uuiddf.task_id.duplicated(keep='first')]\n",
    "\n",
    "print(len(df_gold))\n",
    "df_gold2 = pd.merge(df_gold, uuiddf, on = 'task_id', how='left' )\n",
    "print(len(df_gold2))\n",
    "\n",
    "\n",
    "dfcat = dfsub[['task_id', 'payload.category_ids']]\n",
    "dfcat = dfcat[~dfcat.task_id.duplicated(keep='first')]\n",
    "print(len(df_gold2))\n",
    "df_gold2 = pd.merge(df_gold2, dfcat, on = 'task_id', how='left' )\n",
    "print(len(df_gold2))\n",
    "\n",
    "df_gold = df_gold2.rename(index=str, columns={'payload.existingRecord.uuid': 'uuid', 'payload.factual_id': \"canonical_uuid\", \n",
    "                                              'payload.category_ids':\"category_ids\", 'payload.existingRecord.latitude': 'latitude', \n",
    "                                              'payload.existingRecord.longitude': 'longitude'})\n",
    "df_gold[\"nonDupes\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## clean Tel \n",
    "print('t', len(df_gold.tel))\n",
    "teldf = result[['task_id', 'tel', 'cleantel']]\n",
    "teldf = (teldf.groupby(['task_id', 'tel','cleantel' ]).size().to_frame(name = 'count').reset_index())\n",
    "teldf = teldf.fillna('')\n",
    "df_gold = df_gold.rename(columns={'tel':'cleantel'})\n",
    "df_gold2 = pd.merge(df_gold, teldf, on= ['task_id', 'cleantel'] , how= 'left' )\n",
    "\n",
    "df_gold = (df_gold2)[~df_gold2.task_id.duplicated(keep='first')]\n",
    "del df_gold['cleantel']\n",
    "\n",
    "print('t', len(df_gold.tel))\n",
    "\n",
    "\n",
    "## clean name\n",
    "print('n', len(df_gold.name))\n",
    "teldf = result[['task_id', 'name', 'cleanname']]\n",
    "teldf = (teldf.groupby(['task_id', 'name','cleanname' ]).size().to_frame(name = 'count').reset_index())\n",
    "teldf = teldf.fillna('')\n",
    "df_gold = df_gold.rename(columns={'name':'cleanname'})\n",
    "print(df_gold.columns)\n",
    "print(teldf.columns)\n",
    "df_gold2 = pd.merge(df_gold, teldf, on= ['task_id', 'cleanname'] , how= 'left' )\n",
    "\n",
    "df_gold = (df_gold2)[~df_gold2.task_id.duplicated(keep='first')]\n",
    "del df_gold['cleanname']\n",
    "\n",
    "print('n', len(df_gold.name))\n",
    "\n",
    "## clean add\n",
    "print('a', len(df_gold.address))\n",
    "\n",
    "## clean name\n",
    "print('n', len(df_gold.address))\n",
    "teldf = result[['task_id', 'address', 'cleanadd']]\n",
    "teldf = (teldf.groupby(['task_id', 'address','cleanadd' ]).size().to_frame(name = 'count').reset_index())\n",
    "teldf = teldf.fillna('')\n",
    "df_gold = df_gold.rename(columns={'address':'cleanadd'})\n",
    "df_gold2 = pd.merge(df_gold, teldf, on= ['task_id', 'cleanadd'] , how= 'left' )\n",
    "\n",
    "df_gold = (df_gold2)[~df_gold2.task_id.duplicated(keep='first')]\n",
    "del df_gold['cleanadd']\n",
    "\n",
    "print('a', len(df_gold.address))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_gold2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-17236f434b07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_gold2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_gold2' is not defined"
     ]
    }
   ],
   "source": [
    "df_gold2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AU = df_gold[df_gold.country == 'au']\n",
    "US = df_gold[df_gold.country == 'us']\n",
    "CA = df_gold[df_gold.country == 'ca']\n",
    "GB = df_gold[df_gold.country == 'gb']\n",
    "FR = df_gold[df_gold.country == 'fr']\n",
    "IT = df_gold[df_gold.country == 'it']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'uuid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3810b8afd813>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_gold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_gold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'6d17a66f-1fd0-4219-9b59-291b132b4d35'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3614\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'uuid'"
     ]
    }
   ],
   "source": [
    "#df_gold[df_gold.uuid == '6d17a66f-1fd0-4219-9b59-291b132b4d35']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "metadata": {},
   "outputs": [],
   "source": [
    "AU = (AU.groupby(['canonical_uuid', 'nonDupes'], as_index=False)\n",
    " .apply(lambda x: x[['uuid','name', 'address', 'locality',\n",
    "                             'region', 'postcode', 'latitude', 'longitude', 'tel', \n",
    "                             'website', 'category_ids']].to_dict('r')).reset_index().rename(columns={0:'factual_gold'}).to_json('AU.json', orient='records'))\n",
    "\n",
    "US = (US.groupby(['canonical_uuid', 'nonDupes'], as_index=False)\n",
    " .apply(lambda x: x[['uuid','name', 'address', 'locality',\n",
    "                             'region', 'postcode', 'latitude', 'longitude', 'tel', \n",
    "                             'website', 'category_ids']].to_dict('r')).reset_index().rename(columns={0:'factual_gold'}).to_json('US.json', orient='records'))\n",
    "\n",
    "CA = (CA.groupby(['canonical_uuid', 'nonDupes'], as_index=False)\n",
    " .apply(lambda x: x[['uuid','name', 'address', 'locality',\n",
    "                             'region', 'postcode', 'latitude', 'longitude', 'tel', \n",
    "                             'website', 'category_ids']].to_dict('r')).reset_index().rename(columns={0:'factual_gold'}).to_json('CA.json', orient='records'))\n",
    "\n",
    "\n",
    "GB = (GB.groupby(['canonical_uuid', 'nonDupes'], as_index=False)\n",
    " .apply(lambda x: x[['uuid','name', 'address', 'locality',\n",
    "                             'region', 'postcode', 'latitude', 'longitude', 'tel', \n",
    "                             'website', 'category_ids']].to_dict('r')).reset_index().rename(columns={0:'factual_gold'}).to_json('GB.json', orient='records'))\n",
    "\n",
    "FR = (FR.groupby(['canonical_uuid', 'nonDupes'], as_index=False)\n",
    " .apply(lambda x: x[['uuid','name', 'address', 'locality',\n",
    "                             'region', 'postcode', 'latitude', 'longitude', 'tel', \n",
    "                             'website', 'category_ids']].to_dict('r')).reset_index().rename(columns={0:'factual_gold'}).to_json('FR.json', orient='records'))\n",
    "\n",
    "IT = (IT.groupby(['canonical_uuid', 'nonDupes'], as_index=False)\n",
    " .apply(lambda x: x[['uuid','name', 'address', 'locality',\n",
    "                             'region', 'postcode', 'latitude', 'longitude', 'tel', \n",
    "                             'website', 'category_ids']].to_dict('r')).reset_index().rename(columns={0:'factual_gold'}).to_json('IT.json', orient='records'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1142-f0ccbbc8a4b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mIT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'website'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'http://saintlouis-rome.net'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>website</th>\n",
       "      <th>country</th>\n",
       "      <th>locality</th>\n",
       "      <th>postcode</th>\n",
       "      <th>region</th>\n",
       "      <th>uuid</th>\n",
       "      <th>canonical_uuid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>category_ids</th>\n",
       "      <th>nonDupes</th>\n",
       "      <th>tel</th>\n",
       "      <th>count_x</th>\n",
       "      <th>name</th>\n",
       "      <th>count_y</th>\n",
       "      <th>address</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>59338</td>\n",
       "      <td>http://saintlouis-rome.net</td>\n",
       "      <td>it</td>\n",
       "      <td>Roma</td>\n",
       "      <td>00186</td>\n",
       "      <td>Roma</td>\n",
       "      <td>fedad4f2-9d6d-40e0-a4cb-b3df0e3ffbcb</td>\n",
       "      <td>fedad4f2-9d6d-40e0-a4cb-b3df0e3ffbcb</td>\n",
       "      <td>41.899599771229994</td>\n",
       "      <td>12.474538469029127</td>\n",
       "      <td>[55]</td>\n",
       "      <td></td>\n",
       "      <td>06 688271</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Saint Louis des Français</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Piazza di S. Luigi de’ Francesi</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     task_id                     website country locality postcode region  \\\n",
       "265    59338  http://saintlouis-rome.net      it     Roma    00186   Roma   \n",
       "\n",
       "                                     uuid  \\\n",
       "265  fedad4f2-9d6d-40e0-a4cb-b3df0e3ffbcb   \n",
       "\n",
       "                           canonical_uuid            latitude  \\\n",
       "265  fedad4f2-9d6d-40e0-a4cb-b3df0e3ffbcb  41.899599771229994   \n",
       "\n",
       "              longitude category_ids nonDupes        tel  count_x  \\\n",
       "265  12.474538469029127         [55]           06 688271      5.0   \n",
       "\n",
       "                         name  count_y                          address  count  \n",
       "265  Saint Louis des Français      1.0  Piazza di S. Luigi de’ Francesi    1.0  "
      ]
     },
     "execution_count": 1355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IT[IT.task_id ==59338]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sourceUrl</th>\n",
       "      <th>task_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>file_x</th>\n",
       "      <th>_original_category</th>\n",
       "      <th>_records_touched</th>\n",
       "      <th>address</th>\n",
       "      <th>address_accuracy</th>\n",
       "      <th>address_extended</th>\n",
       "      <th>...</th>\n",
       "      <th>rbdi</th>\n",
       "      <th>region</th>\n",
       "      <th>tel</th>\n",
       "      <th>type</th>\n",
       "      <th>website</th>\n",
       "      <th>cleansite</th>\n",
       "      <th>cleanadd</th>\n",
       "      <th>cleanname</th>\n",
       "      <th>cleantel</th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>166597</td>\n",
       "      <td>https://yny.com/166597</td>\n",
       "      <td>59338</td>\n",
       "      <td>25</td>\n",
       "      <td>it-seed-inputs.json</td>\n",
       "      <td>{'mapping_not_necessary': ['55']}</td>\n",
       "      <td>crawl</td>\n",
       "      <td>Piazza di S. Luigi de’ Francesi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roma</td>\n",
       "      <td>06 688271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://saintlouis-rome.net</td>\n",
       "      <td>saintlouis-rome.net</td>\n",
       "      <td>piazza di s. luigi de’ francesi</td>\n",
       "      <td>saint louis des français</td>\n",
       "      <td>06688271</td>\n",
       "      <td>5933825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>161496</td>\n",
       "      <td>https://yny.com/161496</td>\n",
       "      <td>59338</td>\n",
       "      <td>37</td>\n",
       "      <td>it-seed-inputs.json</td>\n",
       "      <td>{'mapping_not_necessary': ['55']}</td>\n",
       "      <td>crawl</td>\n",
       "      <td>Via di Santa Giovanna d'Arco 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roma</td>\n",
       "      <td>06 688271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://saintlouis-rome.net</td>\n",
       "      <td>saintlouis-rome.net</td>\n",
       "      <td>via di santa giovanna d'arco 5</td>\n",
       "      <td>comunità san luigi dei francesi</td>\n",
       "      <td>06688271</td>\n",
       "      <td>5933837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>161492</td>\n",
       "      <td>https://yny.com/161492</td>\n",
       "      <td>59338</td>\n",
       "      <td>44</td>\n",
       "      <td>it-seed-inputs.json</td>\n",
       "      <td>{'mapping_not_necessary': ['55']}</td>\n",
       "      <td>crawl</td>\n",
       "      <td>Via di Santa Giovanna d'Arco 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roma</td>\n",
       "      <td>06 688271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://saintlouis-rome.net</td>\n",
       "      <td>saintlouis-rome.net</td>\n",
       "      <td>via di santa giovanna d'arco 5</td>\n",
       "      <td>comunità san luigi dei francesi</td>\n",
       "      <td>06688271</td>\n",
       "      <td>5933844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id               sourceUrl task_id user_id               file_x  \\\n",
       "566  166597  https://yny.com/166597   59338      25  it-seed-inputs.json   \n",
       "569  161496  https://yny.com/161496   59338      37  it-seed-inputs.json   \n",
       "570  161492  https://yny.com/161492   59338      44  it-seed-inputs.json   \n",
       "\n",
       "                    _original_category _records_touched  \\\n",
       "566  {'mapping_not_necessary': ['55']}            crawl   \n",
       "569  {'mapping_not_necessary': ['55']}            crawl   \n",
       "570  {'mapping_not_necessary': ['55']}            crawl   \n",
       "\n",
       "                             address address_accuracy address_extended  \\\n",
       "566  Piazza di S. Luigi de’ Francesi              NaN              NaN   \n",
       "569   Via di Santa Giovanna d'Arco 5              NaN              NaN   \n",
       "570   Via di Santa Giovanna d'Arco 5              NaN              NaN   \n",
       "\n",
       "      ...    rbdi region        tel type                     website  \\\n",
       "566   ...     NaN   Roma  06 688271  NaN  http://saintlouis-rome.net   \n",
       "569   ...     NaN   Roma  06 688271  NaN  http://saintlouis-rome.net   \n",
       "570   ...     NaN   Roma  06 688271  NaN  http://saintlouis-rome.net   \n",
       "\n",
       "               cleansite                         cleanadd  \\\n",
       "566  saintlouis-rome.net  piazza di s. luigi de’ francesi   \n",
       "569  saintlouis-rome.net   via di santa giovanna d'arco 5   \n",
       "570  saintlouis-rome.net   via di santa giovanna d'arco 5   \n",
       "\n",
       "                           cleanname  cleantel   unique  \n",
       "566         saint louis des français  06688271  5933825  \n",
       "569  comunità san luigi dei francesi  06688271  5933837  \n",
       "570  comunità san luigi dei francesi  06688271  5933844  \n",
       "\n",
       "[3 rows x 40 columns]"
      ]
     },
     "execution_count": 1354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result.website ==\"http://saintlouis-rome.net\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59041, 59062, 59063, 59151, 59247, 59273, 59287, 59291, 59299,\n",
       "       59310, 59321, 59336, 59363, 59371, 59401, 59404, 59428, 59436,\n",
       "       59454, 59456, 59463, 59465, 59470, 59533, 59576, 59624, 59625,\n",
       "       59665, 59706, 59736, 59799, 59839, 59840, 59911, 59913, 59930,\n",
       "       59936, 59988, 59990, 60011, 60021, 60069])"
      ]
     },
     "execution_count": 948,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notgold.task_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "perf = result[ (result.user_id == 43)| \n",
    "                  (result.user_id == 47) |  (result.user_id == 58) |  (result.user_id == 22) \n",
    "                   | (result.user_id == 59)|  (result.user_id == 38)|  (result.user_id == 26) |(result.user_id == 20)| \n",
    "                  (result.user_id == 21) |  (result.user_id == 25) |  (result.user_id == 33) \n",
    "                   | (result.user_id == 31) |(result.user_id == 20)| \n",
    "                  (result.user_id == 21) |  (result.user_id == 25) |  (result.user_id == 33) \n",
    "                   | (result.user_id == 31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n",
      "Empty DataFrame\n",
      "Columns: [id, sourceUrl, task_id, user_id, file_x, _original_category, _records_touched, address, address_accuracy, address_extended, address_type_code, admin_region, alcohol, alcohol_bar, alcohol_beer_wine, category_ids, country, cuisine, current, file_y, languages, locality, melissa_address_key, melissa_code, name, og_address, po_box, post_town, postcode, raw_address, rbdi, region, tel, type, website, cleansite, cleanadd, cleanname, cleantel, unique]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate(list(notgold.task_id.unique())):\n",
    "    \n",
    "    print(perf[perf.task_id ==int(v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_id  tel           \n",
       "59033    (08) 9168 7300    5\n",
       "59034    (928) 638-7888    4\n",
       "59035    (780) 425-5379    5\n",
       "59036    (212) 363-3200    4\n",
       "59037    (702) 678-5600    5\n",
       "59038    01634 335882      4\n",
       "         0370 333 1181     1\n",
       "59039    02 35 71 38 49    4\n",
       "59040    (413) 586-0350    5\n",
       "59041    01 70 36 39 50    5\n",
       "59042    06 4274 0571      5\n",
       "59043    041 529 8711      1\n",
       "         041 724 1040      3\n",
       "59044    01386 438333      5\n",
       "59045    01 39 10 94 11    5\n",
       "59046    0577 940008       1\n",
       "         0577 940328       4\n",
       "59047    (580) 353-4869    5\n",
       "59048    13 74 68          2\n",
       "         1300 130 372      1\n",
       "59049    03 68 98 51 52    1\n",
       "         03 68 98 51 60    4\n",
       "59050    0418 862 260      5\n",
       "59051    02 41 40 24 40    5\n",
       "59052    (215) 965-2305    5\n",
       "59053    01242 545454      5\n",
       "59054    04 78 31 11 33    5\n",
       "59055    (02) 9231 8111    5\n",
       "59056    (651) 290-1200    5\n",
       "59057    0481 7731         1\n",
       "                          ..\n",
       "60056    080 521 3704      2\n",
       "         080 575 4201      1\n",
       "         0984 181 1234     1\n",
       "         0984 27485        1\n",
       "60057    (03) 5023 3823    5\n",
       "60058    (509) 633-2143    2\n",
       "         (509) 633-9265    3\n",
       "60059    075 812301        5\n",
       "60060    05 46 95 60 10    5\n",
       "60061    0 892 89 90 90    3\n",
       "60062    (514) 877-7373    5\n",
       "60063    (541) 548-7501    3\n",
       "         (800) 551-6949    2\n",
       "60064    (02) 8251 7800    2\n",
       "         1800 199 657      3\n",
       "60065    (978) 744-0180    4\n",
       "         (978) 744-1692    1\n",
       "60066    05 53 06 86 00    1\n",
       "         05 53 06 97 05    4\n",
       "60067    06 7766 6011      1\n",
       "         06 77666          4\n",
       "60068    (07) 5581 5100    5\n",
       "60069    0845 094 9273     2\n",
       "         0845 643 9215     3\n",
       "60070    01330 833463      4\n",
       "         0844 493 2164     1\n",
       "60071    03 83 85 30 01    5\n",
       "60072    (02) 9895 7500    5\n",
       "60073    (808) 742-2623    5\n",
       "60074    0931 65068        2\n",
       "Length: 1342, dtype: int64"
      ]
     },
     "execution_count": 956,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.groupby(['task_id', 'tel']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['batch_id', 'created_at', 'id', 'payload.comment', 'payload.country',\n",
       "       'payload.edits.address', 'payload.edits.category_ids',\n",
       "       'payload.edits.locality', 'payload.edits.name',\n",
       "       'payload.edits.postcode', 'payload.edits.region', 'payload.edits.tel',\n",
       "       'payload.edits.website', 'payload.existingRecord.address',\n",
       "       'payload.existingRecord.category_ids',\n",
       "       'payload.existingRecord.crosswalk_url_facebook',\n",
       "       'payload.existingRecord.crosswalk_url_foursquare',\n",
       "       'payload.existingRecord.crosswalk_url_grubhub',\n",
       "       'payload.existingRecord.crosswalk_url_lonelyplanet',\n",
       "       'payload.existingRecord.crosswalk_url_opentable',\n",
       "       'payload.existingRecord.crosswalk_url_singleplatform',\n",
       "       'payload.existingRecord.crosswalk_url_stubhub',\n",
       "       'payload.existingRecord.crosswalk_url_tripadvisor',\n",
       "       'payload.existingRecord.crosswalk_url_twitter',\n",
       "       'payload.existingRecord.crosswalk_url_wikipedia',\n",
       "       'payload.existingRecord.crosswalk_url_yelp',\n",
       "       'payload.existingRecord.crosswalk_url_zagat',\n",
       "       'payload.existingRecord.latitude', 'payload.existingRecord.locality',\n",
       "       'payload.existingRecord.longitude', 'payload.existingRecord.name',\n",
       "       'payload.existingRecord.postcode', 'payload.existingRecord.region',\n",
       "       'payload.existingRecord.tel', 'payload.existingRecord.uuid',\n",
       "       'payload.existingRecord.website', 'payload.factual_id',\n",
       "       'payload.issueType', 'skips_count', 'updated_at'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origdf = dftask[['payload.existingRecord.name',\n",
    "       'payload.existingRecord.postcode', \n",
    "       'payload.existingRecord.tel', \n",
    "       'payload.existingRecord.website',]]\n",
    "origdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
