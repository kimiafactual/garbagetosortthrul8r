{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "au-extracted.json\n",
      "it-extracted.json\n",
      "fr-extracted.json\n",
      "1\n",
      "gb-extracted.json\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "ca-extracted.json\n",
      "1\n",
      "2\n",
      "us-extracted.json\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "ca-seed-inputs.json  i\n",
      "it-seed-inputs.json  i\n",
      "us-seed-inputs.json  i\n",
      "au-seed-inputs.json  i\n",
      "gb-seed-inputs.json  i\n",
      "fr-seed-inputs.json  i\n"
     ]
    }
   ],
   "source": [
    "#Important notes: All those greater than 5 had consensus.\n",
    "import numpy as np\n",
    "from IPython.core.display import HTML\n",
    "import json\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## THIS IS THE FINAL JUN 8 at 3\n",
    "finaltaskusdf = pd.DataFrame()\n",
    "finallocdf = pd.DataFrame()\n",
    "data = {}\n",
    "all_df= []\n",
    "df_s = pd.DataFrame()\n",
    "files =  ['au-extracted.json','it-extracted.json', \n",
    "          'fr-extracted.json','gb-extracted.json',\n",
    "             'ca-extracted.json', 'us-extracted.json']\n",
    "              \n",
    "\n",
    "for file_num, file_name in enumerate(files):\n",
    "    data = {}\n",
    "    print(str(file_name))\n",
    "    n=0\n",
    "    with open('/Users/kimia/Desktop/Work5/sprint614/' + str(file_name)) as f:\n",
    "            \n",
    "                for line in f:\n",
    "                    try:\n",
    "\n",
    "                        data.update(json.loads( line.rstrip('\\n')))\n",
    "                        all_df.append(data)\n",
    "\n",
    "                        taskusedits = pd.Series(data['data']['extraction']['payload']).to_frame().T\n",
    "                        taskusedits['id'] = (data['uri'])\n",
    "                        taskusedits['file'] = str(file_name)\n",
    "\n",
    "                        locdf = pd.Series(data['data']['extraction']['rawPayload']).to_frame().T\n",
    "                        locdf['id'] = (data['uri'])\n",
    "                        locdf['file'] = str(file_name)\n",
    "\n",
    "\n",
    "                        finaltaskusdf = pd.concat([taskusedits, finaltaskusdf], axis=0)\n",
    "                        finallocdf = pd.concat([locdf, finallocdf], axis=0)\n",
    "       \n",
    "                    except:\n",
    "\n",
    "                        n = n+1\n",
    "                        print(n)\n",
    "finallocdf['id'] = finallocdf['id'].apply(lambda x: int(x[-6:]))\n",
    "finaltaskusdf['id']= finaltaskusdf['id'].apply(lambda x: int(x[-6:]))\n",
    "\n",
    "## THIS WORK!! 1:36 JUN 7\n",
    "data = {}\n",
    "df_s = pd.DataFrame()\n",
    "files = ['ca-seed-inputs.json' ,\n",
    "             'it-seed-inputs.json', 'us-seed-inputs.json', 'au-seed-inputs.json', \n",
    "             'gb-seed-inputs.json' , \n",
    "             'fr-seed-inputs.json']\n",
    "for file_num, file_name in enumerate(files):\n",
    "\n",
    "    print(str(file_name)+\"  i\")\n",
    "    with open('/Users/kimia/Desktop/Work5/sprint614/' + str(file_name)) as f:\n",
    "        \n",
    "        \n",
    "        for line in f:\n",
    "            data.update(json.loads( line.rstrip('\\n')))\n",
    "            #print(data['data']['extraction']['inputMeta'])\n",
    "\n",
    "            d1 = pd.Series(data['data']['extraction']['inputMeta']).to_frame().T \n",
    "        \n",
    "            d1['file'] = str(file_name)\n",
    "            df_s = pd.concat([df_s, d1], axis=0)\n",
    "        \n",
    "result = (pd.merge(df_s,finaltaskusdf, on = ['id'])) # correct merge: (result.file_x == result.file_y)\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "result['cleansite'] =result['website'].apply(lambda x: urlparse(str(x)).netloc)\n",
    "result['cleansite'] =result['cleansite'].apply(lambda x: (str(x).replace(\"www.\", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MODERATION: CONSENSUS AMONG ATTRIBUTES ONCE REMOVING NULL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fr</th>\n",
       "      <th>gb</th>\n",
       "      <th>au</th>\n",
       "      <th>us</th>\n",
       "      <th>it</th>\n",
       "      <th>ca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.831395</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleansite</th>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.664179</td>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.623053</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>0.715385</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.758065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tel</th>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.739837</td>\n",
       "      <td>0.843023</td>\n",
       "      <td>0.750916</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def consensus(df, column):\n",
    "    lowagreement = df.groupby([ 'task_id', str(column)]).size().to_frame(name = 'count').reset_index()\n",
    "    agree5 = lowagreement[lowagreement['count'] >4]\n",
    "    perc5 = (len(agree5.task_id.unique())/len(lowagreement.task_id.unique()))\n",
    "    accuracy = ({str(column):perc5})\n",
    "    return accuracy  \n",
    "\n",
    "final = pd.DataFrame()\n",
    "accuracydict={}\n",
    "\n",
    "columnsz = [\n",
    " 'address',\n",
    " 'name',\n",
    " 'tel',\n",
    " 'cleansite']\n",
    "listy2 = []\n",
    "for number,country in enumerate(result.file_x.unique()):\n",
    "    \n",
    "    for i, v in enumerate(columnsz): \n",
    "        \n",
    "        #get a list of all task IDs with Null, for a given country and attribute\n",
    "        removeNA = result\n",
    "        removeNA[str(v)] = removeNA[str(v)].fillna('KIMIA')\n",
    "\n",
    "        ff = result.groupby([ 'task_id', str(v)]).size().to_frame(name = 'count').reset_index()\n",
    "        dfwithnull = ff[ff[str(v)] == \"KIMIA\"]\n",
    "\n",
    "        ## now have a fresh df, \n",
    "        df_without_null = result\n",
    "        for num,task_id in enumerate(list(dfwithnull.task_id)): \n",
    "            df_without_null = df_without_null[df_without_null.task_id != (task_id)]\n",
    "        #(rr.tel).isnull().sum(axis=0)\n",
    "        percent = (consensus(df_without_null[df_without_null.file_x ==str(country)], str(v)))\n",
    "        countrydf = df_without_null[df_without_null.file_x ==str(country)]\n",
    "        countryfulldf = result[result.file_x ==str(country)]\n",
    "        listy = list([country, v, len(countrydf.task_id.unique()), len(countryfulldf.task_id.unique()), \\\n",
    "              (len(countrydf.task_id.unique())/len(countryfulldf.task_id.unique()))])\n",
    "        accuracydict.update(percent)\n",
    "        listy2.append(listy)\n",
    "    all_perc_disagree = pd.Series(accuracydict).to_frame().sort_values([0],ascending = True)\n",
    "    all_perc_disagree.columns = [str(country[0:2])]\n",
    "    final = pd.concat([all_perc_disagree, final], axis=1)\n",
    "    #print(\"% disagreement by column in \",str(country[0:2]) )\n",
    "    \n",
    "print(\"    MODERATION: CONSENSUS AMONG ATTRIBUTES ONCE REMOVING NULL\")\n",
    "display(HTML(((final).to_html())))\n",
    "\n",
    "#Here I dropped any task_Id where there was an NA--> which would have obviously dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
